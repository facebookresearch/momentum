{#- Jinja2 macros for DRY CMake configuration -#}

{#- Base CMake args shared by all platforms -#}
{%- macro cmake_base_args() %}
    "-DBUILD_SHARED_LIBS=OFF",
    "-DMOMENTUM_BUILD_PYMOMENTUM=ON",
    "-DMOMENTUM_BUILD_EXAMPLES=OFF",
    "-DMOMENTUM_BUILD_TESTING=OFF",
    "-DMOMENTUM_BUILD_RENDERER=OFF",
    "-DMOMENTUM_ENABLE_SIMD=OFF",
{%- endmacro %}

{#- Linux-specific args for manylinux compatibility -#}
{%- macro cmake_linux_args() %}
{{ cmake_base_args() }}
    "-DCMAKE_CXX_SCAN_FOR_MODULES=OFF",
    "-DMOMENTUM_USE_SYSTEM_RERUN_CPP_SDK=ON",
    # Use bundled pybind11 to avoid CMake FindPython Development.Module requirement
    # The pixi environment's pybind11 uses pybind11NewTools which requires python3_add_library
    # from CMake's FindPython, but manylinux Python only has Interpreter component
    "-DMOMENTUM_USE_SYSTEM_PYBIND11=OFF",
    # Use manylinux container's compiler (gcc-toolset-12) instead of pixi's GCC 14.3
    # to ensure manylinux_2_28 compatibility (requires GLIBCXX <= 3.4.24, CXXABI <= 1.3.11)
    "-DCMAKE_CXX_FLAGS=-static-libstdc++ -static-libgcc",
    "-DCMAKE_C_FLAGS=-static-libgcc",
{%- endmacro %}

{#- macOS-specific args -#}
{%- macro cmake_macos_args() %}
{{ cmake_base_args() }}
    "-DCMAKE_CXX_SCAN_FOR_MODULES=OFF",
    "-DMOMENTUM_USE_SYSTEM_RERUN_CPP_SDK=OFF",
    "-DMOMENTUM_USE_SYSTEM_PYBIND11=ON",
{%- endmacro %}

{#- Windows-specific args (maintains original order with -G after SHARED_LIBS) -#}
{%- macro cmake_windows_args() %}
    "-DBUILD_SHARED_LIBS=OFF",
    "-G Visual Studio 17 2022",
    "-DMOMENTUM_BUILD_PYMOMENTUM=ON",
    "-DMOMENTUM_BUILD_EXAMPLES=OFF",
    "-DMOMENTUM_BUILD_TESTING=OFF",
    "-DMOMENTUM_BUILD_RENDERER=OFF",
    "-DMOMENTUM_ENABLE_SIMD=OFF",
    "-DMOMENTUM_USE_SYSTEM_RERUN_CPP_SDK=ON",
    "-DMOMENTUM_USE_SYSTEM_PYBIND11=ON",
{% if variant == "cpu" %}
    "-DCMAKE_CXX_SCAN_FOR_MODULES=OFF",
{% endif %}
{%- endmacro %}

{#- Common cibuildwheel before-all script for Linux -#}
{%- macro cibw_linux_before_all() %}
# Use local pixi binary if available to avoid network issues
if [ -f /project/pixi_bin ]; then
  echo "Using local pixi binary"
  mkdir -p $HOME/.pixi/bin
  cp /project/pixi_bin $HOME/.pixi/bin/pixi
  chmod +x $HOME/.pixi/bin/pixi
else
  echo "Downloading pixi"
  curl -fsSL https://pixi.sh/install.sh | bash
fi
export PATH=$HOME/.pixi/bin:$PATH

# Install dependencies in a separate directory to avoid conflicts with host's .pixi folder
mkdir -p /tmp/build_env
cp {project}/pixi.toml {project}/pixi.lock {project}/README.md {project}/LICENSE /tmp/build_env/
cd /tmp/build_env
pixi install -e default
{%- endmacro %}

{#- ============================================================================ -#}
{#- MAIN TEMPLATE CONTENT -#}
{#- ============================================================================ -#}

[build-system]
requires = ["scikit-build-core", "pybind11", "setuptools-scm"]
build-backend = "scikit_build_core.build"

[project]
name = "pymomentum-{{ variant }}"
dynamic = ["version"]
description = "A library providing foundational algorithms for human kinematic motion and numerical optimization solvers to apply human motion in various applications ({{ description_suffix }})"
readme = "README.md"
requires-python = ">={{ python_version_min }},<{{ python_version_max }}"
authors = [
    { name = "Meta Reality Labs Research", email = "jeongseok@meta.com" },
]
license = { text = "MIT" }
keywords = [
    "kinematics",
    "motion",
    "optimization",
    "human-motion",
    "inverse-kinematics",
    "forward-kinematics",
    "body-tracking",
    "motion-capture",
    "character-animation",
    "robotics",
{% if variant == "gpu" %}
    "gpu",
    "cuda",
{% else %}
    "cpu",
{% endif %}
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
{% if variant == "gpu" %}
    "Operating System :: POSIX :: Linux",
{% else %}
    "Operating System :: POSIX :: Linux",
    "Operating System :: MacOS",
{% endif %}
    "Programming Language :: C++",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: Implementation :: CPython",
    "Topic :: Scientific/Engineering",
    "Topic :: Scientific/Engineering :: Mathematics",
    "Topic :: Scientific/Engineering :: Physics",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "numpy>=1.20.0",
    "scipy>=1.7.0",
    # PyTorch version constraints - platform and Python version specific
    # Linux: Support latest PyTorch with CUDA
    # macOS: Limited to older PyTorch versions (CPU only)
{% if variant == "gpu" %}
    # GPU package only for Linux
    "torch>={{ torch_min_py312 }},<{{ torch_max_py312 }}; platform_system == 'Linux' and python_version == '3.12'",
    "torch>={{ torch_min_py313 }},<{{ torch_max_py313 }}; platform_system == 'Linux' and python_version == '3.13'",
{% else %}
    # CPU package for Linux and macOS ARM64 (Apple Silicon only - Intel Macs not supported)
    # Linux uses latest PyTorch
    "torch>={{ torch_min_py312 }},<{{ torch_max_py312 }}; platform_system == 'Linux' and python_version == '3.12'",
    "torch>={{ torch_min_py313 }},<{{ torch_max_py313 }}; platform_system == 'Linux' and python_version == '3.13'",
    # macOS ARM64 (Apple Silicon) - PyTorch 2.8+ available
    "torch>={{ torch_min_py312_macos }},<{{ torch_max_py312_macos }}; platform_system == 'Darwin' and platform_machine == 'arm64' and python_version == '3.12'",
    "torch>={{ torch_min_py313_macos }},<{{ torch_max_py313_macos }}; platform_system == 'Darwin' and platform_machine == 'arm64' and python_version == '3.13'",
{% endif %}
]

[project.urls]
Homepage = "https://github.com/facebookresearch/momentum"
Documentation = "https://facebookresearch.github.io/momentum/"
Repository = "https://github.com/facebookresearch/momentum"
"Bug Tracker" = "https://github.com/facebookresearch/momentum/issues"
Changelog = "https://github.com/facebookresearch/momentum/releases"

[tool.scikit-build]
build-dir = "build/{wheel_tag}"
cmake.args = [
{{ cmake_base_args() }}
    "-DCMAKE_CXX_SCAN_FOR_MODULES=OFF",
    "-DMOMENTUM_USE_SYSTEM_RERUN_CPP_SDK=OFF",
    "-DMOMENTUM_USE_SYSTEM_PYBIND11=ON",
    "-DCMAKE_DISABLE_FIND_PACKAGE_Arrow=ON",
]
# Read CMAKE_PREFIX_PATH from environment variable
# This is needed for cibuildwheel where pixi installs deps to a custom location
cmake.define.CMAKE_PREFIX_PATH = {env = "CMAKE_PREFIX_PATH"}
minimum-version = "0.10"
metadata.version.provider = "scikit_build_core.metadata.setuptools_scm"
sdist.exclude = [
    ".github/",
    ".pixi/",
    "build/",
    "dist/",
    "*.lock",
]
wheel.exclude = ["geometry_test_helper.*"]

{% if variant == "cpu" %}
[[tool.scikit-build.overrides]]
if.platform-system = "^darwin"
cmake.args = [
{{ cmake_macos_args() }}
]
cmake.define.CMAKE_PREFIX_PATH = {env = "CMAKE_PREFIX_PATH"}

[[tool.scikit-build.overrides]]
if.platform-system = "^linux"
cmake.args = [
{{ cmake_linux_args() }}
]
cmake.define.CMAKE_PREFIX_PATH = {env = "CMAKE_PREFIX_PATH"}
{% endif %}

{% if variant == "gpu" %}
[[tool.scikit-build.overrides]]
if.platform-system = "^linux"
cmake.args = [
{{ cmake_linux_args() }}
]
cmake.define.CMAKE_PREFIX_PATH = {env = "CMAKE_PREFIX_PATH"}
{% endif %}

[[tool.scikit-build.overrides]]
if.platform-system = "^win32"
cmake.args = [
{{ cmake_windows_args() }}
]
cmake.define.CMAKE_PREFIX_PATH = {env = "CMAKE_PREFIX_PATH"}

[tool.setuptools_scm]
# Automatically determine version from git tags
# Tags should follow the pattern: v1.2.3
# Will generate versions like: 1.2.3 (on tag), 1.2.4.post12 (between tags)
version_scheme = "post-release"
local_scheme = "no-local-version"
version_file = "pymomentum/_version.py"

{% if variant == "cpu" %}
[tool.cibuildwheel]
build = "cp312-* cp313-*"
build-verbosity = 3
# Skip PyPy, musllinux, and Windows for now
# Windows is skipped due to cibuildwheel shell issues with export/command substitution
skip = "pp* *-musllinux* *-win*"
archs = ["auto64"]
manylinux-x86_64-image = "manylinux_2_28"
# Disable build isolation so PyTorch installed by before-build is available for CMake
build-frontend = { name = "pip", args = ["--no-build-isolation"] }

# Common
before-build = """
set -e  # Exit on error

VER=$(python -c "import sys; print(f'{sys.version_info.major}{sys.version_info.minor}')")
echo "Building for Python $VER"

# Copy the Python-version-specific pyproject.toml
if [ -f "pyproject-pypi-cpu-py${VER}.toml" ]; then
  cp pyproject-pypi-cpu-py${VER}.toml pyproject.toml
  echo "Copied pyproject-pypi-cpu-py${VER}.toml"
else
  echo "ERROR: pyproject-pypi-cpu-py${VER}.toml not found!"
  ls -la pyproject*.toml
  exit 1
fi

# Upgrade pip first
echo "Upgrading pip..."
python -m pip install --upgrade pip

# Install build dependencies (required when using --no-build-isolation)
# These are from [build-system].requires in pyproject.toml
echo "Installing build dependencies..."
python -m pip install scikit-build-core pybind11 setuptools-scm

# Install PyTorch (needed at build time to link against libtorch)
# PyTorch is a runtime dependency but also needed at build time for linking
echo "Installing PyTorch for build..."
if [ "$VER" = "312" ]; then
  python -m pip install "torch>={{ torch_min_py312 }},<{{ torch_max_py312 }}" --index-url https://download.pytorch.org/whl/cpu
elif [ "$VER" = "313" ]; then
  python -m pip install "torch>={{ torch_min_py313 }},<{{ torch_max_py313 }}" --index-url https://download.pytorch.org/whl/cpu
else
  echo "Unsupported Python version: $VER"
  exit 1
fi

# Verify torch is installed correctly
echo "Verifying PyTorch installation..."
python -c "import torch; print(f'PyTorch {torch.__version__} installed at {torch.__file__}')"
"""
test-command = "python -c \"import pymomentum\""
test-requires = ["numpy", "scipy"]
before-test = """
VER=$(python -c "import sys; print(f'{sys.version_info.major}{sys.version_info.minor}')")
if [ "$VER" = "312" ]; then
  python -m pip install "torch>={{ torch_min_py312 }},<{{ torch_max_py312 }}" --index-url https://download.pytorch.org/whl/cpu
elif [ "$VER" = "313" ]; then
  python -m pip install "torch>={{ torch_min_py313 }},<{{ torch_max_py313 }}" --index-url https://download.pytorch.org/whl/cpu
fi
"""

[tool.cibuildwheel.linux]
before-all = """
{{ cibw_linux_before_all() }}
"""
# Use manylinux container's gcc-toolset-12 compiler for manylinux_2_28 compatibility
# Pixi provides dependencies (headers/libs) but we use the container's compiler
environment = { PATH = "$HOME/.pixi/bin:$PATH", CMAKE_PREFIX_PATH = "/tmp/build_env/.pixi/envs/default", CONDA_PREFIX = "/tmp/build_env/.pixi/envs/default", MOMENTUM_BUILD_WITH_FBXSDK = "OFF" }
repair-wheel-command = """
# Bundle libraries with auditwheel using linux_x86_64 (no ABI checks)
# Then rename to manylinux_2_28_x86_64 for pip compatibility
# This workaround is needed because conda-forge libraries use GCC 14+ with CXXABI_1.3.15 symbols
# which are incompatible with manylinux_2_28's max CXXABI_1.3.11
export LD_LIBRARY_PATH=/tmp/build_env/.pixi/envs/default/lib:$LD_LIBRARY_PATH

# Create output directory
mkdir -p /tmp/linux_wheel

echo 'Step 1: Bundling libraries with auditwheel (linux_x86_64)...'
auditwheel repair -w /tmp/linux_wheel {wheel} \
    --plat linux_x86_64 \
    --exclude 'libtorch*.so*' \
    --exclude 'libc10*.so*' \
    --exclude 'libmkl*.so*' \
    --exclude 'libgomp*.so*' \
    --exclude 'libpthread*.so*' \
    --exclude 'libc.so*' \
    --exclude 'libc-*.so*' \
    --exclude 'libm.so*' \
    --exclude 'libm-*.so*' \
    --exclude 'libdl*.so*' \
    --exclude 'librt*.so*' \
    --exclude 'libresolv*.so*' \
    --exclude 'libnss*.so*' \
    --exclude 'ld-linux*.so*' \
    --exclude 'libgcc_s*.so*' || (echo 'Auditwheel failed.' && exit 1)

echo 'Step 2: Renaming wheel to manylinux_2_28_x86_64...'
# Check if auditwheel produced output
if [ -z "$(ls /tmp/linux_wheel/*.whl 2>/dev/null)" ]; then
  echo "Warning: auditwheel produced no output, using original wheel"
  WHEEL_NAME=$(basename {wheel})
  NEW_WHEEL_NAME=$(echo "$WHEEL_NAME" | sed 's/linux_x86_64/manylinux_2_28_x86_64/')
  cp {wheel} {dest_dir}/$NEW_WHEEL_NAME
else
  LINUX_WHEEL=$(ls /tmp/linux_wheel/*.whl | head -1)
  WHEEL_NAME=$(basename "$LINUX_WHEEL")
  NEW_WHEEL_NAME=$(echo "$WHEEL_NAME" | sed 's/linux_x86_64/manylinux_2_28_x86_64/')
  cp "$LINUX_WHEEL" {dest_dir}/$NEW_WHEEL_NAME
fi

echo "Created $NEW_WHEEL_NAME"
echo "Note: This wheel requires glibc 2.28+ and libstdc++ from GCC 11+"
"""
{% endif %}

{% if variant == "gpu" %}
[tool.cibuildwheel]
build = "cp312-* cp313-*"
build-verbosity = 3
# GPU builds only for Linux (manylinux)
# Skip PyPy, musllinux, macOS, and Windows
skip = "pp* *-musllinux* *-macosx* *-win*"
archs = ["auto64"]
manylinux-x86_64-image = "manylinux_2_28"
# Disable build isolation so PyTorch installed by before-build is available for CMake
build-frontend = { name = "pip", args = ["--no-build-isolation"] }

# Common
before-build = """
set -e  # Exit on error

VER=$(python -c "import sys; print(f'{sys.version_info.major}{sys.version_info.minor}')")
echo "====================================="
echo "Building GPU wheel for Python $VER"
echo "====================================="

# Check available disk space
echo ">>> Disk space before installation:"
df -h / || true

# Copy the GPU pyproject.toml
echo ">>> Step 1: Copying pyproject-pypi-gpu.toml"
cp pyproject-pypi-gpu.toml pyproject.toml

# Upgrade pip first
echo ">>> Step 2: Upgrading pip..."
python -m pip install --upgrade pip

# Clean pip cache to free up space before large installs
echo ">>> Step 2.5: Cleaning pip cache to free disk space..."
python -m pip cache purge || true

# Install build dependencies (required when using --no-build-isolation)
# These are from [build-system].requires in pyproject.toml
echo ">>> Step 3: Installing build dependencies..."
python -m pip install --no-cache-dir scikit-build-core pybind11 setuptools-scm

# Install PyTorch CPU for building (needed at build time to link against libtorch)
# NOTE: We use CPU PyTorch during build to save ~2GB disk space in the Docker container
# The GPU wheel will still work at runtime with GPU PyTorch because:
# 1. libtorch's API is the same for CPU and GPU versions
# 2. CUDA functionality is loaded dynamically at runtime
# 3. The wheel only links against libtorch (CPU version is sufficient for linking)
# At runtime, users will install GPU PyTorch which provides CUDA support
echo ">>> Step 4: Installing PyTorch CPU for build (to save disk space)..."
if [ "$VER" = "312" ]; then
  python -m pip install --no-cache-dir "torch>={{ torch_min_py312 }},<{{ torch_max_py312 }}" --index-url https://download.pytorch.org/whl/cpu
elif [ "$VER" = "313" ]; then
  python -m pip install --no-cache-dir "torch>={{ torch_min_py313 }},<{{ torch_max_py313 }}" --index-url https://download.pytorch.org/whl/cpu
else
  echo "Unsupported Python version: $VER"
  exit 1
fi

# Verify torch package is installed (optional - skip if fails)
# This verification is not strictly necessary - the build will fail later if torch is missing
echo ">>> Step 5: Verifying PyTorch package installation..."
python -c "import importlib.util; spec = importlib.util.find_spec('torch'); print(f'PyTorch package found at: {spec.origin}')" || echo "Warning: PyTorch verification failed, but continuing anyway..."

# Set CMAKE_PREFIX_PATH to include PyTorch's cmake files
# This allows CMake to find libtorch for linking
echo ">>> Step 6: Setting up CMAKE_PREFIX_PATH for PyTorch..."
TORCH_CMAKE_DIR=$(python -c "import torch; print(torch.utils.cmake_prefix_path)" 2>/dev/null || echo "")
if [ -n "$TORCH_CMAKE_DIR" ] && [ -d "$TORCH_CMAKE_DIR" ]; then
  export CMAKE_PREFIX_PATH="$TORCH_CMAKE_DIR:$CMAKE_PREFIX_PATH"
  echo "CMAKE_PREFIX_PATH=$CMAKE_PREFIX_PATH"
else
  echo "Warning: Could not find PyTorch cmake path, build may fail"
fi

# Show disk space after installation
echo ">>> Disk space after installation:"
df -h / || true

echo "====================================="
echo "Before-build completed for Python $VER"
echo "====================================="
"""
test-command = "python -c \"import pymomentum\""
test-requires = ["numpy", "scipy"]
# For testing, we use CPU PyTorch to save disk space in the Docker container
# The import test doesn't need CUDA - it just verifies the wheel can be imported
# Users will install GPU PyTorch when they use the package
before-test = """
VER=$(python -c "import sys; print(f'{sys.version_info.major}{sys.version_info.minor}')")
if [ "$VER" = "312" ]; then
  python -m pip install --no-cache-dir "torch>={{ torch_min_py312 }},<{{ torch_max_py312 }}" --index-url https://download.pytorch.org/whl/cpu
elif [ "$VER" = "313" ]; then
  python -m pip install --no-cache-dir "torch>={{ torch_min_py313 }},<{{ torch_max_py313 }}" --index-url https://download.pytorch.org/whl/cpu
fi
"""

[tool.cibuildwheel.linux]
before-all = """
# NOTE: We don't install CUDA toolkit from yum because:
# 1. pymomentum doesn't have custom CUDA code (no .cu files)
# 2. PyTorch's CUDA wheel includes all CUDA runtime libraries
# 3. This saves ~2GB of disk space for the PyTorch installation

echo ">>> Disk space at start:"
df -h /

# Set up CUDA environment
export CUDA_HOME=/usr/local/cuda-12.8
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

{{ cibw_linux_before_all() }}
"""
# Use manylinux container's gcc-toolset-12 compiler for manylinux_2_28 compatibility
# Pixi provides dependencies (headers/libs) but we use the container's compiler
# CUDA paths for building GPU extensions
environment = { PATH = "/usr/local/cuda-12.8/bin:$HOME/.pixi/bin:$PATH", CMAKE_PREFIX_PATH = "/tmp/build_env/.pixi/envs/minimal-build", CONDA_PREFIX = "/tmp/build_env/.pixi/envs/minimal-build", MOMENTUM_BUILD_WITH_FBXSDK = "OFF", CUDA_HOME = "/usr/local/cuda-12.8", LD_LIBRARY_PATH = "/usr/local/cuda-12.8/lib64:/tmp/build_env/.pixi/envs/minimal-build/lib" }
repair-wheel-command = """
# Bundle libraries with auditwheel using linux_x86_64 (no ABI checks)
# Then rename to manylinux_2_28_x86_64 for pip compatibility
export LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64:$LD_LIBRARY_PATH

# Create output directory
mkdir -p /tmp/linux_wheel

echo 'Step 1: Bundling libraries with auditwheel (linux_x86_64)...'
auditwheel repair -w /tmp/linux_wheel {wheel} \
    --plat linux_x86_64 \
    --exclude 'libtorch*.so*' \
    --exclude 'libc10*.so*' \
    --exclude 'libmkl*.so*' \
    --exclude 'libgomp*.so*' \
    --exclude 'libcu*.so*' \
    --exclude 'libnv*.so*' \
    --exclude 'libpthread*.so*' \
    --exclude 'libc.so*' \
    --exclude 'libc-*.so*' \
    --exclude 'libm.so*' \
    --exclude 'libm-*.so*' \
    --exclude 'libdl*.so*' \
    --exclude 'librt*.so*' \
    --exclude 'libresolv*.so*' \
    --exclude 'libnss*.so*' \
    --exclude 'ld-linux*.so*' \
    --exclude 'libgcc_s*.so*' || (echo 'Auditwheel failed.' && exit 1)

echo 'Step 2: Renaming wheel to manylinux_2_28_x86_64...'
# Check if auditwheel produced output
if [ -z "$(ls /tmp/linux_wheel/*.whl 2>/dev/null)" ]; then
  echo "Warning: auditwheel produced no output, using original wheel"
  WHEEL_NAME=$(basename {wheel})
  NEW_WHEEL_NAME=$(echo "$WHEEL_NAME" | sed 's/linux_x86_64/manylinux_2_28_x86_64/')
  cp {wheel} {dest_dir}/$NEW_WHEEL_NAME
else
  LINUX_WHEEL=$(ls /tmp/linux_wheel/*.whl | head -1)
  WHEEL_NAME=$(basename "$LINUX_WHEEL")
  NEW_WHEEL_NAME=$(echo "$WHEEL_NAME" | sed 's/linux_x86_64/manylinux_2_28_x86_64/')
  cp "$LINUX_WHEEL" {dest_dir}/$NEW_WHEEL_NAME
fi

echo "Created $NEW_WHEEL_NAME"
echo "Note: This wheel requires glibc 2.28+, CUDA 12.8+, and libstdc++ from GCC 11+"
"""
{% endif %}
