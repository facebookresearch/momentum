[{"title":"Convert Model","type":0,"sectionRef":"#","url":"/momentum/docs/examples/convert_model","content":"Convert Model The convert_model example demonstrates how to convert a character model and its associated animation file between FBX and GLB formats. Use the -m or --model option to specify the input model, followed by the path to the model file (.fbx or .glb). If no input model is provided, the tool will automatically read the animation from an existing GLB or FBX file. convert_model [OPTIONS] Options: -h,--help Print this help message and exit -m,--model TEXT:FILE Input model (.fbx/.glb); not required if reading animation from glb or fbx -p,--parameters TEXT:FILE Input model parameter file (.model) -l,--locator TEXT:FILE Input locator file (.locators) -d,--motion TEXT:FILE Input motion data file (.mmo/.glb/.fbx) -o,--out TEXT REQUIRED Output file (.fbx/.glb) --out-locator TEXT Output a locator file (.locators) --save-markers Save marker data from motion file in output (glb only) -c,--character-mesh (FBX Output file only) Saves the Character Mesh to the output file. Example 1: Convert an fbx model to a glb model. pixi run convert_model -m character.fbx -p character.model -l character.locators -o character.glb Example 2: Convert a glb file to an fbx file with animation curves only (without mesh). pixi run convert_model -d animation.glb -o animation.fbx Example 3: Convert an fbx animation to glb with a given model parameter file. There is no guarantee the conversion is lossless. We will simply use InverseParameterTransform for a least square fit of the parameters. pixi run convert_model -d animation.fbx -p character.model -o animation.glb Example 4: Apply animation from an s0 model to a s4 model for high-res rendering (ie. with mesh). The .model file is needed if the target model is in .fbx format so we know how to map the input motion. pixi run convert_model -m character.fbx -p character.model -d animation_s0.glb -o animation_s4.fbx -c ","keywords":"","version":"Next"},{"title":"Development Environment","type":0,"sectionRef":"#","url":"/momentum/docs/developer_guide/development_environment","content":"","keywords":"","version":"Next"},{"title":"Supported Environments​","type":1,"pageTitle":"Development Environment","url":"/momentum/docs/developer_guide/development_environment#supported-environments","content":" OS: Windows, Linux, macOS  ","version":"Next","tagName":"h2"},{"title":"Package Manager​","type":1,"pageTitle":"Development Environment","url":"/momentum/docs/developer_guide/development_environment#package-manager","content":" Before developing Momentum, it is necessary to install various dependencies. This process can be platform-dependent and tedious. To simplify this, Momentum utilizes Pixi.  Pixi facilitates building Momentum in a virtual environment across different platforms (Windows, macOS Intel/ARM, Linux) using consistent command lines.  For those interested, you can examine the pixi.toml file to see how dependencies are specified and to explore the available Pixi tasks for Momentum.  info If you choose not to use Pixi, you will need to manually install all dependencies using platform-specific package managers. These typically install dependencies into the system directory. Ensure you have the appropriate package managers installed for your OS: Homebrew for macOS, Vcpkg for Windows, and apt for Ubuntu/Debian. After installation, refer to pixi.toml for guidance on what and how to install.  ","version":"Next","tagName":"h2"},{"title":"Running Custom Commands in Shell​","type":1,"pageTitle":"Development Environment","url":"/momentum/docs/developer_guide/development_environment#running-custom-commands-in-shell","content":" To execute additional commands in the virtual environment other than the predefined tasks (to see the full tasks: pixi task list), such as using CMake directly or running an executable, activate the virtual environment with:  pixi shell   To exit the virtual environment, simply run:  exit   ","version":"Next","tagName":"h2"},{"title":"Developing with Microsoft Visual Studio (Windows Only)​","type":1,"pageTitle":"Development Environment","url":"/momentum/docs/developer_guide/development_environment#developing-with-microsoft-visual-studio-windows-only","content":" To open the project in Visual Studio 2022, use the command:  pixi run open_vs  ","version":"Next","tagName":"h3"},{"title":"Process Markers","type":0,"sectionRef":"#","url":"/momentum/docs/examples/process_markers","content":"","keywords":"","version":"Next"},{"title":"Optical Marker based Body Tracking​","type":1,"pageTitle":"Process Markers","url":"/momentum/docs/examples/process_markers#optical-marker-based-body-tracking","content":" This project provides a set of core functions to solve for body motions based on optical marker inputs. It supports all PC OSes (untested on mobile). The marker_tracker lib contains core functionalities for downstream applications to build on. Demo applications are provided to show how they can be used to build your data processing pipeline. process_markers_app solves for body motion given an input marker sequence, with or without an existing calibrated skeleton. refine_motion runs smoothing as a post process to fill in missing data from input. They can be used to batch process mocap data in a python script.  info The Momentum ecosystem implicitly operates in centimeter. If you are working with c3d files, we will do the unit conversion based on the stored unit on file. However, if you are using our API with your own data, make sure to convert them into cm. We also assume a Y-up coordinate system, which is not the industry convention (i.e., Z-up).    ","version":"Next","tagName":"h2"},{"title":"Refine Motion (Post-process noisy tracking motion)","type":0,"sectionRef":"#","url":"/momentum/docs/examples/refine_motion","content":"Refine Motion (Post-process noisy tracking motion) The input marker data may be noisy or contain missing data in a few frames. We can run a smoothing step on the entire sequence to fill in gaps and smooth out noise. Use a config file: pixi run refine_motion -c refine_motion.config Use cli argument to overwrite config values: pixi run refine_motion -c refine_motion.config -i track.glb -o refined.glb --smoothing 2.5 ","keywords":"","version":"Next"},{"title":"Example use cases​","type":1,"pageTitle":"Process Markers","url":"/momentum/docs/examples/process_markers#example-use-cases","content":" Get the full list of options for each application with -h or --help argument. 02_01.c3d is an example input file used by the default config files. Note that a config file can be used together with command line options. The command line overwrites values in the config file.  ","version":"Next","tagName":"h2"},{"title":"Track a marker sequence without a calibrated model.​","type":1,"pageTitle":"Process Markers","url":"/momentum/docs/examples/process_markers#track-a-marker-sequence-without-a-calibrated-model","content":" The first step in tracking a marker file is to calibrate the subject's proportions and the markers' placement. It requires a .locators file that defines a template of marker layout on the body. We have a template file with common layouts from Vicon and OptiTrack. There is usually a Range-of-Motion (ROM) sequence captured for this calibration purpose.  Use a config file:  pixi run process_markers -c process_markers_calib.config     Setting the calibrate option to true will first calibrate the skeleton and the marker layout, then use the calibrated model for motion tracking.    ","version":"Next","tagName":"h2"},{"title":"Track a marker sequence with a calibrated model.​","type":1,"pageTitle":"Process Markers","url":"/momentum/docs/examples/process_markers#track-a-marker-sequence-with-a-calibrated-model","content":" The tracking result from the above calibration step contains the calibrated model, and it can then be used to track other motion data from the same subject, without running the calibration step again. We currently only support saving/loading calibrated models in .glb format.  Use a config file:  pixi run process_markers -c process_markers_tracking.config     Use cli arguments:  pixi run process_markers -i input.c3d -o tracked.glb --model calibrated_model.glb --calibrate false   ","version":"Next","tagName":"h2"},{"title":"Style Guide","type":0,"sectionRef":"#","url":"/momentum/docs/developer_guide/style_guide","content":"","keywords":"","version":"Next"},{"title":"Code Formatting​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#code-formatting","content":" To format your code, run:  pixi run lint   This uses clang-format with the specific version defined in pixi.toml to ensure consistent formatting across all C++ source files.  ","version":"Next","tagName":"h2"},{"title":"Error Handling​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#error-handling","content":" Momentum uses exceptions for handling unrecoverable errors, which is essential for a lower-level library like this. Throwing exceptions allows error detection mechanisms to have visibility into these errors and prevents silent failures, which may lead to more severe bugs. By choosing exceptions as the primary method for error handling in Momentum, we ensure that unrecoverable errors are easily detectable, and the Momentum library remains user-friendly for developers interacting with the application layer.  Using exceptions is especially crucial when considering the application layer as the user of the Momentum library. For layers closer to the services, everything should be surrounded by try-catch blocks to prevent server crashes while still providing valuable error information. Python programmers, who often interact with the application layer, typically expect exceptions, making it a more reasonable approach for error handling in Momentum.  One important caution is to avoid using exceptions for flow control; common errors, such as &quot;L2 norm is too high,&quot; should not result in exceptions being thrown.  ","version":"Next","tagName":"h2"},{"title":"Alternative Approaches​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#alternative-approaches","content":" std::options​  While optional types can be acceptable in some cases, they can lead to the loss of error information, which is not ideal for the application layer. We use optional types for inputs that can be missing for a few frames due to reasons such as lost tracking, but in these cases, the specific reason is not critical.  folly::Expected​  Folly::Expected acts like an optional type but allows for an error type to be specified (see documentation here). This can be useful in some APIs, particularly if error codes need to be serialized or for other similar purposes. In general, folly::Expected is preferred over std::optional.  ","version":"Next","tagName":"h3"},{"title":"Array Access​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#array-access","content":" When accessing elements within arrays, the Momentum codebase employs two methods: the .at() method and the [] operator. The choice between these two methods should be made based on the considerations of performance, safety, and the intended audience of the code:  It is recommended to use the [] operator for code that is self-contained and developed by the Momentum team, especially for low-level and performance-critical code. The [] operator does not perform bounds checking, thus offering better performance. Conversely, the .at() method should be considered for areas of code that might be accessed by the user as it performs bounds checking to prevent out-of-range errors, enhancing the safety of the code.  ","version":"Next","tagName":"h3"},{"title":"Design Decisions​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#design-decisions","content":" ","version":"Next","tagName":"h2"},{"title":"Prefer gsl::span over typed container like std::vector as function argument​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#prefer-gslspan-over-typed-container-like-stdvector-as-function-argument","content":" Using std::vector&lt;T&gt; as a function argument requires the call site to create an std::vector&lt;T&gt; instance even when the data is already stored in a compatible memory layout, such as contiguous memory. By switching to gsl::span&lt;T&gt;, call sites can avoid creating an additional std::vector&lt;T&gt; object and benefit from improved performance by not requiring an unnecessary data copy.  ","version":"Next","tagName":"h3"},{"title":"Header Include Style​","type":1,"pageTitle":"Style Guide","url":"/momentum/docs/developer_guide/style_guide#header-include-style","content":" Momentum follows standard C++ conventions for header includes, using different syntax depending on the context:  Public Headers (Use Angle Brackets &lt;&gt;)​  In public Momentum headers that are installed for users, use angle brackets:  // In public header files (e.g., momentum/character/character.h) #include &lt;momentum/common/checks.h&gt; #include &lt;momentum/math/mesh.h&gt;   Rationale: Angle brackets instruct the compiler to search in system/standard include paths. When Momentum is installed as a library, downstream users and build systems will treat these as system headers and look for them in the appropriate system locations (e.g., /usr/local/include, /opt/include).  Library Implementation Source Files (Use Quotes &quot;&quot;)​  In library implementation source files (.cpp files in core library directories), use quotes:  // In library implementation .cpp files #include &quot;momentum/character/character.h&quot; #include &quot;momentum/common/checks.h&quot;   Rationale: Quotes instruct the compiler to first search in local/relative directories before falling back to system paths. This ensures that during Momentum's own build process, the compiler finds the local development headers rather than any previously installed system versions.  Tests, Tutorials, and Examples (Use Angle Brackets &lt;&gt;)​  In tests, tutorials, and example code, use angle brackets:  // In test files, tutorials, and examples #include &lt;momentum/character/character.h&gt; #include &lt;momentum/common/checks.h&gt;   Rationale: Tests, tutorials, and examples represent user-facing code that demonstrates how external developers should consume the Momentum library. They should mirror the external user experience by using angle brackets as users would when the library is installed as a system library. This also serves as documentation showing the correct way to include headers. ","version":"Next","tagName":"h3"},{"title":"Creating Your Applications","type":0,"sectionRef":"#","url":"/momentum/docs/user_guide/creating_your_applications","content":"","keywords":"","version":"Next"},{"title":"Install Momentum​","type":1,"pageTitle":"Creating Your Applications","url":"/momentum/docs/user_guide/creating_your_applications#install-momentum","content":" First, install Momentum in the virtual environment by running:  pixi run install   This command builds (in Release mode) and installs Momentum to .pixi/envs/default/{include,lib,share}/ (Windows may have slightly different path). The necessary environment variables are set so that CMake can find Momentum (and other dependencies) using the environment variables in the virtual environment.  ","version":"Next","tagName":"h2"},{"title":"Writing Source Code​","type":1,"pageTitle":"Creating Your Applications","url":"/momentum/docs/user_guide/creating_your_applications#writing-source-code","content":" Create a new file named main.cpp in your project root with the following content:  #include &lt;momentum/math/mesh.h&gt; using namespace momentum; int main() { auto mesh = Mesh(); mesh.updateNormals(); return EXIT_SUCCESS; }   ","version":"Next","tagName":"h2"},{"title":"Writing CMake Script​","type":1,"pageTitle":"Creating Your Applications","url":"/momentum/docs/user_guide/creating_your_applications#writing-cmake-script","content":" Create a CMakeLists.txt file in the same directory as main.cpp.  To add momentum to your CMake project, first find the momentum package using thefind_package function and then add the appropriate momentum::&lt;target&gt; as a dependency to your library or executable. For example, if you want to use the character functionality from momentum, you would add momentum::character as a dependency:  cmake_minimum_required(VERSION 3.16.3) project(momentum) find_package(momentum CONFIG REQUIRED) add_executable(hello_world main.cpp) target_link_libraries(hello_world PRIVATE momentum::math)   Refer to the example project located at momentum/examples/hello_world/ for the complete source code.  If you are developing a library that depends on Momentum:  add_library(my_lib SHARED my_lib.hpp my_lib.cpp) # shared add_library(my_lib STATIC my_lib.hpp my_lib.cpp) # static target_link_libraries(my_lib PUBLIC momentum::math)   ","version":"Next","tagName":"h2"},{"title":"Building using CMake​","type":1,"pageTitle":"Creating Your Applications","url":"/momentum/docs/user_guide/creating_your_applications#building-using-cmake","content":" Assuming your project directory now contains:  &lt;root&gt; - CMakeLists.txt - main.cpp   For convenience, we assume that your project root is located at momentum/examples/hello_world/ because this code example is provided in that directory. You can use this working example as a reference, but feel free to adjust the path according to your actual project root.  Here, we assume you are not using Pixi to build your project, but you are still within the Pixi environment for managing dependencies.  To run any command in the virtual environment, use:  pixi run &lt;command&gt;   Run the native CMake commands in the virtual environment as follows:  To configure the application, run:  # Linux and macOS pixi run cmake -S momentum/examples/hello_world -B momentum/examples/hello_world/build -DCMAKE_BUILD_TYPE=Release # Windows pixi run cmake -S momentum/examples/hello_world -B momentum/examples/hello_world/build   To build the application, run:  # Linux and macOS pixi run cmake --build momentum/examples/hello_world/build # Windows pixi run cmake --build momentum/examples/hello_world/build --config Release   ","version":"Next","tagName":"h2"},{"title":"Run the Application​","type":1,"pageTitle":"Creating Your Applications","url":"/momentum/docs/user_guide/creating_your_applications#run-the-application","content":" Execute the application with:  # Linux and macOS ./momentum/examples/hello_world/build/hello_world # Windows momentum/examples/hello_world/build/Release/hello_world.exe   ","version":"Next","tagName":"h2"},{"title":"Configuring Your Project with Pixi​","type":1,"pageTitle":"Creating Your Applications","url":"/momentum/docs/user_guide/creating_your_applications#configuring-your-project-with-pixi","content":" If you wish to use Pixi for your project similar to how it's implemented in Momentum, please visit this website for detailed instructions. ","version":"Next","tagName":"h2"},{"title":"Viewers","type":0,"sectionRef":"#","url":"/momentum/docs/examples/viewers","content":"","keywords":"","version":"Next"},{"title":"GLB Viewer​","type":1,"pageTitle":"Viewers","url":"/momentum/docs/examples/viewers#glb-viewer","content":" To run the GLB viewer, use the following command:  pixi run glb_viewer --input &lt;my_file.glb&gt;       Source Code  ","version":"Next","tagName":"h2"},{"title":"FBX Viewer​","type":1,"pageTitle":"Viewers","url":"/momentum/docs/examples/viewers#fbx-viewer","content":" To run the FBX viewer, use the following command:  pixi run fbx_viewer --input &lt;my_file.fbx&gt;     Source Code  ","version":"Next","tagName":"h2"},{"title":"C3D Viewer​","type":1,"pageTitle":"Viewers","url":"/momentum/docs/examples/viewers#c3d-viewer","content":" To run the C3D viewer, use the following command:  pixi run c3d_viewer --input &lt;my_file.c3d&gt;     Source Code  ","version":"Next","tagName":"h2"},{"title":"URDF Viewer​","type":1,"pageTitle":"Viewers","url":"/momentum/docs/examples/viewers#urdf-viewer","content":" To run the URDF viewer, use the following command:  pixi run urdf_viewer --input &lt;my_file.urdf&gt;     Source Code  For example, you can download an Atlas robot from this link, which may look like:   ","version":"Next","tagName":"h2"},{"title":"Design Decisions","type":0,"sectionRef":"#","url":"/momentum/pymomentum/developer_guide/design_decisions","content":"","keywords":"","version":"Next"},{"title":"NumPy vs PyTorch Tensors​","type":1,"pageTitle":"Design Decisions","url":"/momentum/pymomentum/developer_guide/design_decisions#numpy-vs-pytorch-tensors","content":" PyMomentum mixes NumPy arrays and PyTorch tensors throughout the codebase. This explains the reasoning and current status.  ","version":"Next","tagName":"h2"},{"title":"Why the Mixed Approach?​","type":1,"pageTitle":"Design Decisions","url":"/momentum/pymomentum/developer_guide/design_decisions#why-the-mixed-approach","content":" Old Reason (Historical):  Auto-conversion from Eigen types to NumPy arrays works natively in pybind11Can use Python buffer interface to wrap data without copiesPyTorch tensors are &quot;more painful to work with&quot; in pybind11Used PyTorch only where differentiability was needed  Internal Convention:  PyTorch tensor = differentiable operationNumPy array = non-differentiable operation  New Reason (Current):The dependence on aten makes building Python code that uses torch.Tensor somewhat challenging compared to code that uses the basic buffer interface:  Blocking pymomentum usage in downstream projectsPreventing demonstration projectsCausing various compatibility problems  ","version":"Next","tagName":"h3"},{"title":"Current State​","type":1,"pageTitle":"Design Decisions","url":"/momentum/pymomentum/developer_guide/design_decisions#current-state","content":" The codebase is mixed which can be confusing because we're between approaches. Discussions are happening around:  Stripping all PyTorch from pymomentum.geometryIsolating differentiability (and hence PyTorch dependencies) in specific libraries, such as diff_solverUsing GPU_character for ML workloads instead  Examples:  solver2 uses NumPy arrays (not differentiable, PyTorch-independent)Batching support being removed from non-ML contexts (like rendering)Rendering code will strip batch support for open sourcing  PyTorch advantages being lost:  Extra tensor manipulation functionalityBatching/unbatching supportBut interfaces become more confusing for non-ML use  ","version":"Next","tagName":"h3"},{"title":"Future Directions​","type":1,"pageTitle":"Design Decisions","url":"/momentum/pymomentum/developer_guide/design_decisions#future-directions","content":" Potential approach: If you need batching + differentiability + GPU support, use GPU_character instead of pymomentum. This would let us:  Strip enormous amounts of code from pymomentumFix build system issuesSimplify interfaces  (Obviously could only happen after open sourcing GPU_character)  Current recommendation: Accept manual conversions between NumPy/PyTorch until the architecture stabilizes. ","version":"Next","tagName":"h3"},{"title":"Development Environment","type":0,"sectionRef":"#","url":"/momentum/pymomentum/developer_guide/development_environment","content":"Development Environment This section will contain PyMomentum development environment setup instructions. Coming soon...","keywords":"","version":"Next"},{"title":"Troubleshooting Guide","type":0,"sectionRef":"#","url":"/momentum/docs/user_guide/troubleshooting_guide","content":"","keywords":"","version":"Next"},{"title":"FBX Retargeting: Incorrect Bind Pose​","type":1,"pageTitle":"Troubleshooting Guide","url":"/momentum/docs/user_guide/troubleshooting_guide#fbx-retargeting-incorrect-bind-pose","content":" Problem: FBX shows correctly in fbx_viewer but fails to convert to GLB or produces wrong joint transforms.  Cause: Retargeting changes joint ordering, making skeleton incompatible with Momentum format.  Solution:  The core approach involves creating a joint name mapping between retargeted and expected joint names, then applying this mapping to reorder skeleton states before conversion.  Identify Joint Mapping: Compare joint names between retargeted FBX and expected character formatApply Remapping: Use mapping to reorder skeleton states to match expected formatConvert to Transforms: Apply SkeletonState::compare() to validate and convert to joint transforms  Validation:  See test/io/io_fbx_test.cpp::Fbx_Retargeting_JointRemapping for a complete working example that:  Simulates the joint reordering problem (demonstrates failure without remapping)Implements the remapping solution (demonstrates success with remapping)Validates that remapping significantly improves skeleton state accuracy  Tools:  fbx_viewer: Visual validation of FBX filesconvert_model: Convert between FBX and GLB formatsglb_viewer: Validate converted GLB results  Related Examples:  Viewers Guide: Visual validation tools for different file formatsConvert Model: Comprehensive FBX/GLB conversion examples ","version":"Next","tagName":"h2"},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/momentum/docs/user_guide/getting_started","content":"","keywords":"","version":"Next"},{"title":"Installing Momentum​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#installing-momentum","content":" Momentum C++ binary builds are available for Windows, macOS, and Linux via Pixi or the Conda package manager.  For Windows, please install Visual Studio 2022 or greater.  ","version":"Next","tagName":"h2"},{"title":"Pixi​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#pixi","content":" pixi add momentum-cpp   ","version":"Next","tagName":"h3"},{"title":"Conda​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#conda","content":" conda install -c conda-forge momentum-cpp   ","version":"Next","tagName":"h3"},{"title":"Building Momentum from Source​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#building-momentum-from-source","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisite​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#prerequisite","content":" Complete the following steps only once:  Install Pixi by following the instructions on https://prefix.dev/ Clone the repository and navigate to the root directory: git clone https://github.com/facebookresearch/momentum cd momentum Ensure that all subsequent commands are executed in the project's root directory unless specified otherwise.  ","version":"Next","tagName":"h3"},{"title":"Build and Test​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#build-and-test","content":" Build the project with the following command (note that the first run may take a few minutes as it installs all dependencies): pixi run build Run the tests with: pixi run test   To view all available command lines, run pixi task list.  ","version":"Next","tagName":"h3"},{"title":"Hello World Example​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#hello-world-example","content":" To run the hello_world example:  pixi run hello_world   Alternatively, you can directly run the executable:  # Linux and macOS ./build/hello_world # Windows ./build/Release/hello_world.exe   ","version":"Next","tagName":"h3"},{"title":"Running Other Examples​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#running-other-examples","content":" To run other examples:  pixi run glb_viewer --help   For more examples, please refer to the Examples page.  ","version":"Next","tagName":"h3"},{"title":"Clean Up​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#clean-up","content":" If you need to start over for any reason:  pixi run clean   Momentum uses the build/ directory for CMake builds, and .pixi/ for the Pixi virtual environment. You can clean up everything by either manually removing these directories or by running the command above.  ","version":"Next","tagName":"h3"},{"title":"FBX Support​","type":1,"pageTitle":"Getting Started","url":"/momentum/docs/user_guide/getting_started#fbx-support","content":" Momentum uses OpenFBX to load Autodesk's FBX file format, which is enabled by default. To save files in FBX format, you must install the FBX SDK 2020.3.  Linux​  The FBX SDK will be automatically installed when you run pixi run config, so no additional steps are required.  macOS and Windows​  You can download it from Autodesk's website or use direct links (macOS, Windows). After installing the SDK, build Momentum from source with MOMENTUM_BUILD_WITH_FBXSDK=ON option as:  # macOS MOMENTUM_BUILD_WITH_FBXSDK=ON pixi run &lt;target&gt; # Windows (Powershell) $env:MOMENTUM_BUILD_WITH_FBXSDK = &quot;ON&quot;; pixi run &lt;target&gt; # Windows (cmd) set MOMENTUM_BUILD_WITH_FBXSDK=ON &amp;&amp; pixi run &lt;target&gt;   For example, file conversion can be run as follows:  # Windows (Powershell) $env:MOMENTUM_BUILD_WITH_FBXSDK = &quot;ON&quot;; pixi run convert_model -d &lt;input.glb&gt; -o &lt;out.fbx&gt;  ","version":"Next","tagName":"h3"},{"title":"Examples","type":0,"sectionRef":"#","url":"/momentum/pymomentum/examples/python_basics","content":"Examples This section will contain PyMomentum examples and tutorials. Coming soon...","keywords":"","version":"Next"},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/momentum/pymomentum/user_guide/getting_started","content":"","keywords":"","version":"Next"},{"title":"Installing PyMomentum​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#installing-pymomentum","content":" PyMomentum binary builds are available for Windows, macOS, and Linux via Pixi or the Conda package manager.  ","version":"Next","tagName":"h2"},{"title":"Pixi​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#pixi","content":" # Auto-detects GPU/CPU pixi add pymomentum # With specific backend pixi add pymomentum-gpu # or pymomentum-cpu   ","version":"Next","tagName":"h3"},{"title":"Conda​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#conda","content":" # Replace 'pixi add' with 'conda install -c conda-forge' conda install -c conda-forge pymomentum conda install -c conda-forge pymomentum-gpu # or pymomentum-cpu   ","version":"Next","tagName":"h3"},{"title":"Building PyMomentum from Source​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#building-pymomentum-from-source","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisite​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#prerequisite","content":" Complete the following steps only once:  Install Pixi by following the instructions on the website. Clone the repository and navigate to the root directory: git clone https://github.com/facebookresearch/momentum cd momentum Ensure that all subsequent commands are executed in the project's root directory unless specified otherwise.  ","version":"Next","tagName":"h3"},{"title":"Build and Test​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#build-and-test","content":" Build the project with the following command (note that the first run may take a few minutes as it installs all dependencies): pixi run build Run the Python tests with: pixi run test_py   ","version":"Next","tagName":"h3"},{"title":"Building from Source for Custom Environments​","type":1,"pageTitle":"Getting Started","url":"/momentum/pymomentum/user_guide/getting_started#building-from-source-for-custom-environments","content":" If you need to use PyMomentum in your own conda environment with specific dependency versions (e.g., particular PyTorch or CUDA versions), you have two options:  Option 1: Add your code/packages to the pixi environment (recommended for quick testing)​  For quick testing and development, you can add your packages or code to the existing pixi environment by modifying pixi.toml:  # Add a package dependency to pixi.toml pixi add your-package-name # Or manually edit pixi.toml to add your custom dependencies   This approach avoids the complexity of managing dependencies manually and ensures compatibility with the pixi-managed environment.  Option 2: Build in your custom conda environment​  For production use or when you need specific dependency versions:  Activate your target conda environment: conda activate your_environment_name Navigate to the momentum source directory: cd path/to/momentum Install required dependencies: When building with pip install . in your custom environment, you need to manually install PyMomentum's dependencies. See the dependencies section in pixi.toml for the complete list of required packages. Key dependencies include: # Install core dependencies (adjust versions as needed) conda install -c conda-forge pytorch eigen ceres-solver Build and install PyMomentum: pip install . This builds and installs PyMomentum using the dependencies in your activated environment.  Troubleshooting​  I built the latest unreleased version with pixi run build_py. Can I use it in my conda environment?  No. pixi run build_py builds within pixi's isolated environment. To use the latest version in your conda environment, activate it and run pip install . as shown above.  Finding available PyMomentum versions:  pixi search -c conda-forge pymomentum # or conda search -c conda-forge pymomentum   Installing specific versions with CUDA constraints:  # Example: Install version 0.1.74 with CUDA 12.9 conda install -c conda-forge pymomentum=0.1.74=&quot;cuda129*&quot;   Dependency conflicts or version incompatibility:  Ensure your environment has compatible PyTorch, CUDA, and build dependencies (scikit-build-core, pybind11, CMake, C++ compiler)PyMomentum links against PyTorch's CUDA libraries, so CUDA versions must matchFor custom PyTorch/CUDA combinations not available on conda-forge, build from source (as described above) or contribute a backport to the momentum-feedstock repository ","version":"Next","tagName":"h3"},{"title":"Visualization using pymomentum rasterizer","type":0,"sectionRef":"#","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer","content":"","keywords":"","version":"Next"},{"title":"Why render on the CPU?​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#why-render-on-the-cpu","content":" The obvious choice for visualization for anyone with a graphics background is to render using a GPU, which will be super-fast and provide instant feedback. However, this is often a bad idea on the cluster because cloud GPUs are expensive and use significant energy, so using these GPUs to render images can be quite wasteful. Regardless, almost any rendering job using a sufficiently fast rasterizer (such as our own) is more likely to be bottlenecked by I/O bandwidth than rendering speed so you would see minimal speed gains from even the fastest GPU.  ","version":"Next","tagName":"h2"},{"title":"Why a software rasterizer?​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#why-a-software-rasterizer","content":" There are many options for visualizing data, and it is extremely nonobvious why we would want to have our own software rasterizer.  Software or hardware OpenGL: challenging to work with, little error checking, many silent failures that generate missing output. Global state is challenging to manage. Doesn't support arbitrary camera models unless you implement custom shaders.Blender/professional tools: Can produce very pretty soft shadows etc but challenging to work with on the cluster and don't natively support fisheye camera models unless you build a complicated lens shader.WebGL-based visualization: Very nice when working in Jupyter notebooks but totally unsuitable for rendering in batch. Doesn't natively support our camera models OR standard OpenGL shaders so properly rendering with our camera models can be extremely challenging.Pytorch3d: optimized for differentiable rendering, very slow on CPU.  ","version":"Next","tagName":"h2"},{"title":"What is pymomentum rasterizer?​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#what-is-pymomentum-rasterizer","content":" Pymomentum rasterizer is a fully-featured rasterizer.  Cross-platform: Implemented using drjit's SIMD wrappers so it runs on both Intel and ARM.Fast: Runs roughly 2x faster than MesaGL's software OpenGL emulation.Threadsafe: releases the Python GIL so you can easily run it multithreaded (e.g. render multiple images or multiple frames at once). Compare with e.g. OpenGL which has tons of internal state.Full per-pixel lighting and shading with multiple lights.Runs completely on the CPU: zero OpenGL or GPU dependencies.Easy to use, completely functional interface (no global state as in OpenGL). Good error reporting (e.g. makes sure your indices are reasonable) and sensible defaults (e.g. if you you don't provide a light, a default lighting setup is automatically provided instead of rendering a black frame). Simple to use (just a single import statement).Basic support for texture mapping.Support for ground plane shadows.Can render per-pixel triangle or vertex IDs.Supports arbitrary camera models, provided you provide an implementation compliant with the interface in momentum/renderer/camera.h.Includes 2d primitives (lines, circles) as well with depth buffer support.  ","version":"Next","tagName":"h2"},{"title":"Using the rasterizer​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#using-the-rasterizer","content":" ","version":"Next","tagName":"h2"},{"title":"Getting started​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#getting-started","content":" Cameras​  The first thing you need is a camera. Pymomentum's rasterizer uses the pymomentum.renderer.Camera class. You can construct one in a few ways:  You can construct a camera with an intrinsics model and optional extrinsics matrix.If you have a pymomentum body model, you can use pymomentum.renderer.build_cameras_for_body() to create a camera that looks at the body and frames it in view.You can construct a default camera and set the extrinsics matrix explicitly, using e.g. camera.look_at().You can use camera.frame() to frame a set of 3d points in view (this can be handy for ensuring that an entire animation stays in frame).  Note that the camera determines the image resolution, you can always use camera.upsample() to scale up the image as needed for better quality.  import pymomentum.renderer as pym_renderer import numpy as np image_height, image_width = 800, 1000 # Create a pinhole intrinsics model intrinsics = pym_renderer.PinholeIntrinsicsModel( image_width=image_width, image_height=image_height, fx=800.0, # focal length in pixels fy=800.0, cx=image_width / 2.0, # principal point cy=image_height / 2.0 ) # Create a camera with the intrinsics camera = pym_renderer.Camera(intrinsics) # Move the camera along -z and look at the origin camera = camera.look_at( position=np.array([0, 0, 1]), target=np.zeros(3), up=np.array([0, 1, 0]) ) # Make sure the entire object is in view: camera = camera.frame(vertex_positions)   Depth/Image buffers​  Now you need to create depth and RGB buffers to render onto. This is very easy now that you have a camera.  import pymomentum.renderer as pym_renderer z_buffer = pym_renderer.create_z_buffer(camera) rgb_buffer = pym_renderer.create_rgb_buffer(camera)   Note: the buffer size will get padded out to the nearest multiple of 8 for better SIMD performance. You can correct this after the rendering is complete using standard slicing:  z_buffer = z_buffer[:,:camera.image_width] rgb_buffer = rgb_buffer[:,:camera.image_height]   ","version":"Next","tagName":"h3"},{"title":"3d primitives​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#3d-primitives","content":" Meshes​  Now, rasterizing a mesh onto the image is a single function call.  pym_renderer.rasterize_mesh(vertex_positions, vertex_normals, triangles, camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer)   If you have multiple meshes to render, you just call rasterize_mesh repeatedly using the same z_buffer.  There is a special function to simplify rasterizing posed pymomentum Characters that takes in a skeleton state:  skel_state = pym_geometry.model_parameters_to_skeleton_state(character, model_params) pym_renderer.rasterize_character(character, skel_state, camera, z_buffer, rgb_buffer)   The default render uses a basic material (white diffuse) and a basic but usable lighting setup where the light is co-located with the camera. If you want a shinier setup, you can change the material:  mat = pym_renderer.PhongMaterial(diffuse_color=np.array([0.8, 0.9, 1.0]), specular_color=np.ones(3) * 0.3) pym_renderer.rasterize_mesh(vertex_positions, vertex_normals, triangles, camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer, material=mat)   If you want to render a wireframe on your mesh, you can use this command:  pym_renderer.rasterize_wireframe(vertex_positions, triangles, camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer)   Spheres and cylinders​  There is special functionality for rendering spheres and cylinders.  sphere_centers = torch.stack( [torch.arange(-10, 10, 3), 5 * torch.ones(7), torch.ones(7)] ).transpose(0, 1) pym_renderer.rasterize_spheres( sphere_centers, camera, z_buffer, rgb_buffer=rgb_buffer, radius=torch.ones(7) ) pym_renderer.rasterize_cylinders( start_position=torch.tensor([[-5, 8, 0]]), end_position=torch.tensor([[5, 8, 0]]), camera=camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer )   You also generate a nice checkerboard ground plane (y defaults to up, but you can change this with the model_matrix if needed).  pym_renderer.rasterize_checkerboard( camera=camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer, )   Transforms​  You can also transform any object by passing a model transform, the rasterizer is capable of dealing with nonuniform scale and shearing:  xf = np.array( [[1, 0, 0, 0], [0, 0.3, 0, 5], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=np.float32 ) pym_renderer.rasterize_mesh(vertex_positions, vertex_normals, triangles, camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer, material=mat, model_matrix=xf)   Skeletons​  Because Character skeletons are so important to working with momentum, we have some extra functionality for rendering them.  pym_renderer.rasterize_skeleton(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, style=pym_renderer.SkeletonStyle.Pipes, image_offset=np.asarray([-600, 0]), sphere_radius=1.0, cylinder_radius=0.5) pym_renderer.rasterize_skeleton(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, style=pym_renderer.SkeletonStyle.Octahedrons, sphere_radius=1.0) pym_renderer.rasterize_skeleton(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, style=pym_renderer.SkeletonStyle.Lines, image_offset=np.asarray([600, 0]), sphere_radius=5.0, cylinder_radius=2.0, sphere_material=pym_renderer.PhongMaterial(np.asarray([1, 0.6, 0.6])))   There are three different skeleton &quot;styles&quot;: &quot;Pipes&quot; (3d cylinders and spheres), &quot;Octahedrons&quot; (this asymmetric octahedron shape, useful for visualizing rotations) and &quot;Lines&quot; (2d lines and circles).  ","version":"Next","tagName":"h3"},{"title":"2d primitives​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#2d-primitives","content":" It can be useful to render 2d primitives like circles and lines but have them respect the z buffer. This can be used:  To create a nice grid on the ground plane.To render e.g. 3d keypoints (also see the note below about using a depth offset).  Now, spheres and cylinders work pretty well for these needs, but (1) lines and circles are significantly faster since approximating a sphere requires &gt;100 triangles (2) lines and circles have radius/thickness values defined in pixels instead of worldspace units, making tuning their size easier (3) lines and circles can look more aesthetically pleasing depending on the use case.  pym_renderer.rasterize_lines( positions=line_positions, camera=camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer, thickness=2.0, color=np.array([1.0, 0.0, 0.0]) # Red lines ) pym_renderer.rasterize_circles( positions=circle_positions, camera=camera, z_buffer=z_buffer, rgb_buffer=rgb_buffer, radius=5.0, line_thickness=1.0, line_color=np.array([0.0, 1.0, 0.0]) # Green circles )   Note that aliasing can be particularly bad for lines so see the notes about antialiasing below.  ","version":"Next","tagName":"h3"},{"title":"Rendering on top of existing images​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#rendering-on-top-of-existing-images","content":" If you want to render on top of an existing image, you can use the alpha_matte function. This will automatically downsample the image if necessary (if it was upsampled for anti-aliasing reasons) and handle conversions between float- and uint8-valued buffers.  import cv2 tgt_image = cv2.imread(...) # OpenCV likes to use BGR but we use RGB tgt_image = tgt_image[..., ::-1] rgb_buffer = pym_renderer.create_rgb_buffer(camera) z_buffer = pym_renderer.create_z_buffer(camera) # Target image is a [height x width x 3] float- or uint8-valued array: pym_renderer.alpha_matte(z_buffer, rgb_buffer, tgt_image)   ","version":"Next","tagName":"h3"},{"title":"Using depth offset for clearer skeleton/keypoint rendering​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#using-depth-offset-for-clearer-skeletonkeypoint-rendering","content":" A classic approach to rendering e.g. 3d keypoints is to render circles on top of the image. The problem with this approach is that because the depth buffer is not respected, the keypoints will be visible through the mesh. This can be very confusing to look at. Notice in the left character how the skeleton of the right hand is visible all the way through the character, which makes it hard to see what is going on.  We can use the z buffer to correct this, but if we try to rasterize the skeleton to the same image where the mesh is the skeleton will be completely hidden. Passing a depth_offset to the rasterizer bumps the skeleton forward, allowing you to see the parts of the skeleton that are just below the mesh surface but still hiding parts of the skeleton that are far behind (the right image).  pym_renderer.rasterize_character(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, image_offset=np.asarray([300, 0]), material=pym_renderer.PhongMaterial(np.asarray([1, 0.6, 0.6]))) # Use depth_offset to bump the skeleton forward so we can see it &quot;through&quot; the mesh: pym_renderer.rasterize_skeleton(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, style=pym_renderer.SkeletonStyle.Pipes, sphere_radius=1.0, cylinder_radius=0.5, depth_offset=-15, image_offset=np.asarray([300, 0]))   In addition, you can pass an image_offset (in pixels) to any rasterizer function and it will displace a mesh in image-space.  # Render body and skeleton side-by-side using image_offset: pym_renderer.rasterize_character(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, image_offset=np.asarray([-300, 0]), material=pym_renderer.PhongMaterial(np.asarray([1, 0.6, 0.6]))) pym_renderer.rasterize_skeleton(character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, style=pym_renderer.SkeletonStyle.Octahedrons, sphere_radius=1.0, cylinder_radius=0.5, depth_offset=-15, image_offset=np.asarray([300, 0]))   ","version":"Next","tagName":"h3"},{"title":"Ground plane shadows​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#ground-plane-shadows","content":" Shadows can be very helpful in debugging lower body motion. The rasterizer does not support fully general shadows but there is a basic old-school OpenGL trick you can use to generate a nice shadow on the ground plane.  Basically, we can rasterize the mesh projected down onto the ground plane. This is done as a two-step process: the first rasterizes the mesh, generating a depth buffer, and the second splats this shadow onto the ground.  # Two lights, the first is above the person and casts shadows while the other # is co-located with the camera to ensure good fill. lights = [pym_renderer.Light.create_point_light( np.asarray([-20, 200, 30]), color=np.asarray([0.7, 0.7, 0.7]) ), pym_renderer.Light.create_point_light( camera.center_of_projection, np.asarray([0.3, 0.3, 0.3]), )] # Create a separate z buffer for the shadows. shadow_buffer = pym_renderer.create_z_buffer(camera) # Rasterize the body mesh onto the shadow Z buffer using a projection matrix # constructed from the first light: pym_renderer.rasterize_character( character, skel_state, camera, z_buffer=shadow_buffer, model_matrix=pym_renderer.create_shadow_projection_matrix(lights[0]), back_face_culling=False, # Disable back-face culling in case the project inverts triangles. ) # Rasterizer the ground plane to our RGB buffer: pym_renderer.rasterize_checkerboard(camera, z_buffer, rgb_buffer, width=500, subdivisions=3) # Use the shadow z buffer to darken the ground plane wherever the shadow hits: very_far = 10000.0 rgb_buffer *= ( torch.logical_or(shadow_buffer &gt; very_far, z_buffer &gt; very_far) .to(torch.float) .clamp(0.5, 1.0) .unsqueeze(-1) ) # Finally rasterize the character mesh: pym_renderer.rasterize_character( character, skel_state, camera, z_buffer, rgb_buffer=rgb_buffer, lights=lights )   ","version":"Next","tagName":"h3"},{"title":"Generating a video​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#generating-a-video","content":" For video generation, you can use standard video writing libraries like OpenCV or ffmpeg-python. The basic idea is to render each frame to a buffer, and then write the buffer to a video file.  import cv2 # Initialize video writer fourcc = cv2.VideoWriter_fourcc(*'mp4v') video_writer = cv2.VideoWriter(file_path, fourcc, video_fps, (video_width, video_height)) for i_frame in range(n_frames): full_image = np.zeros(shape=(video_height, video_width, 3), dtype=np.uint8) # ... render your frame ... # Convert RGB to BGR for OpenCV bgr_image = full_image[..., ::-1] video_writer.write(bgr_image) video_writer.release()   ","version":"Next","tagName":"h3"},{"title":"Multithreading​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#multithreading","content":" As noted above, pymomentum.renderer works well in a multithreaded setting. The simplest way to leverage this is using multiprocessing.dummy.Pool():  def rasterize_one_frame(frame_idx: int): # ... your rendering code here ... return rendered_image n_threads = 4 fourcc = cv2.VideoWriter_fourcc(*'mp4v') video_writer = cv2.VideoWriter( os.path.join(out_path, &quot;animation.mp4&quot;), fourcc, 30, (image_width, image_height) ) with multiprocessing.dummy.Pool(n_threads) as pool: for idx, image in enumerate( pool.imap(rasterize_one_frame, frames_to_write) ): # Convert RGB to BGR for OpenCV bgr_image = image[..., ::-1] video_writer.write(bgr_image) if idx % 10 == 0: print(f&quot;Write frame {idx} of {len(frames_to_write)}&quot;) video_writer.release()   Typically the speedup you get is bottlenecked by the serial parts (video encoding, Python overhead) so you won't see a perfectly linear speedup, but in the above code I saw a roughly 3x speedup on 4 threads (60s-20s) and a 4x speedup on 8 threads (60s-15s). Note that this is a sequence of 675 frames (with shadows and 2x supersampling) and we are getting ~45fps on 8 threads.  ","version":"Next","tagName":"h3"},{"title":"Subdivision​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#subdivision","content":" One potential drawback of rasterizing is that we only apply camera distortion to vertices, and the interpolation between vertices is linear. If you have very large objects, you will start to notice that triangles aren't &quot;bending&quot; the way you'd expect toward the edge of wide-angle cameras. The way to address this is to break the mesh into smaller triangles, and pymomentum.renderer provides functionality to do this with the subdivide_mesh function:  subdivided_vertices, subdivided_normals, subdivided_triangles, _, _ = pym_renderer.subdivide_mesh( vertices=vertex_positions, normals=vertex_normals, triangles=triangles, levels=2, # Number of subdivision levels max_edge_length=10.0 # Maximum edge length before subdivision )   The function will subdivide triangles based on:  levels: Number of subdivision iterations to performmax_edge_length: Maximum allowed edge length - longer edges will be broken into smaller triangles.  ","version":"Next","tagName":"h3"},{"title":"Other buffers​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#other-buffers","content":" The rasterizer knows how to render other quantities as well.  The vertex_index_buffer rasterizes the index of the vertex to the buffer, or -1 for empty pixels.The triangle_index_buffer rasterizes the index of the triangle to the buffer, or -1 for empty pixels.The surface_normals_buffer rasterizes the direction of the surface normal in eye coordinates, or all zeros if empty pixels.  These last two buffers can be used for things like per-part segmentation (use the rendered vertex indices to look up into a vertex index to part ID mapping).  # Default index buffer is set to -1 everywhere (this is because vertex # indices start at 0) vertex_index_buffer = pym_renderer.create_index_buffer(camera) triangle_index_buffer = pym_renderer.create_index_buffer(camera) normals_buffer = pym_renderer.create_rgb_buffer(camera) pym_renderer.rasterize_character(character, skel_state, camera, z_buffer=z_buffer, surface_normals_buffer=normals_buffer, vertex_index_buffer=vertex_index_buffer, triangle_index_buffer=triangle_index_buffer, ) # Generate some random colors: random_colors = torch.rand( max(triangles.shape[0], vertices.shape[0]), 3, dtype=torch.float32 ) # Need to shift by 1 since empty pixels are set to -1 (torch tensor indexing doesn't # appear to support -1). triangle_colors = random_colors[triangle_index_buffer.flatten() + 1, :].reshape( rgb_buffer.shape ) vertex_colors = random_colors[vertex_index_buffer.flatten() + 1, :].reshape( rgb_buffer.shape )   From left: RGB buffer, normals buffer, triangle index buffer, vertex index buffer (notice the Voronoi regions).  ","version":"Next","tagName":"h3"},{"title":"Antialiasing​","type":1,"pageTitle":"Visualization using pymomentum rasterizer","url":"/momentum/pymomentum/examples/visualization_pymomentum_rasterizer#antialiasing","content":" The rasterizer doesn't do any antialiasing, so you may see some jagged edges in your renders. This will probably be less important for meshes but is going to be particularly noticeable for thin structures like lines or thin cylinders. This is easy to fix by supersampling the image, just create a larger camera using camera.upsample() and then downsample at the end.  import pymomentum.renderer as pym_renderer sup_samp: int = 2 cam_supersample = cam.upsample(sup_samp) z_buffer = pym_renderer.create_z_buffer(cam_supersample) rgb_buffer = pym_renderer.create_rgb_buffer(cam_supersample) # render pym_renderer.rasterize_mesh(...) output_image = np.zeros(shape=(cam.image_height, cam.image_width, 3) # Alpha_matte function knows how to handle alpha with upsampled cameras (will # correctly blend along edges using the averaged alpha). pym_renderer.alpha_matte(z_buffer, rgb_buffer, output_image)   No supersampling vs with supersampling provides significantly better visual quality. ","version":"Next","tagName":"h3"}]