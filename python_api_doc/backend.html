

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pymomentum.backend &mdash; PyMomentum  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pymomentum.gpu_character" href="gpu_character.html" />
    <link rel="prev" title="pymomentum.marker_tracking" href="marker_tracking.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            PyMomentum
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="geometry.html">pymomentum.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="quaternion.html">pymomentum.quaternion</a></li>
<li class="toctree-l1"><a class="reference internal" href="skel_state.html">pymomentum.skel_state</a></li>
<li class="toctree-l1"><a class="reference internal" href="trs.html">pymomentum.trs</a></li>
<li class="toctree-l1"><a class="reference internal" href="solver.html">pymomentum.solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="solver2.html">pymomentum.solver2</a></li>
<li class="toctree-l1"><a class="reference internal" href="marker_tracking.html">pymomentum.marker_tracking</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">pymomentum.backend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-pymomentum.backend.skel_state_backend">pymomentum.backend.skel_state_backend module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT"><code class="docutils literal notranslate"><span class="pre">GlobalSkelStateFromLocalSkelStateJIT</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state"><code class="docutils literal notranslate"><span class="pre">global_skel_state_from_local_skel_state()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state_backprop"><code class="docutils literal notranslate"><span class="pre">global_skel_state_from_local_skel_state_backprop()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state_no_grad"><code class="docutils literal notranslate"><span class="pre">global_skel_state_from_local_skel_state_no_grad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.skel_state_backend.unpose_from_momentum_global_joint_state"><code class="docutils literal notranslate"><span class="pre">unpose_from_momentum_global_joint_state()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-pymomentum.backend.trs_backend">pymomentum.backend.trs_backend module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT"><code class="docutils literal notranslate"><span class="pre">ForwardKinematicsFromLocalTransformationJIT</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state"><code class="docutils literal notranslate"><span class="pre">global_trs_state_from_local_trs_state()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state_forward_only"><code class="docutils literal notranslate"><span class="pre">global_trs_state_from_local_trs_state_forward_only()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.trs_backend.unpose_from_global_joint_state"><code class="docutils literal notranslate"><span class="pre">unpose_from_global_joint_state()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-pymomentum.backend.utils">pymomentum.backend.utils module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#backend-utility-functions-for-pymomentum">Backend Utility Functions for PyMomentum</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.utils.LBSAdapter"><code class="docutils literal notranslate"><span class="pre">LBSAdapter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.utils.calc_fk_prefix_multiplication_indices"><code class="docutils literal notranslate"><span class="pre">calc_fk_prefix_multiplication_indices()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pymomentum.backend.utils.flatten_skinning_weights_and_indices"><code class="docutils literal notranslate"><span class="pre">flatten_skinning_weights_and_indices()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpu_character.html">pymomentum.gpu_character</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyMomentum</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">pymomentum.backend</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/backend.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-pymomentum.backend">
<span id="pymomentum-backend"></span><h1>pymomentum.backend<a class="headerlink" href="#module-pymomentum.backend" title="Link to this heading"></a></h1>
<p>PyMomentum Backend</p>
<p>High-performance implementations for forward kinematics and linear blend skinning operations.</p>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
<section id="module-pymomentum.backend.skel_state_backend">
<span id="pymomentum-backend-skel-state-backend-module"></span><h3>pymomentum.backend.skel_state_backend module<a class="headerlink" href="#module-pymomentum.backend.skel_state_backend" title="Link to this heading"></a></h3>
<p>Skeleton State Backend for PyMomentum</p>
<p>This module provides efficient forward kinematics and skinning operations using
the skeleton state representation (8 parameters per joint: translation, quaternion, scale).</p>
<p>The skeleton state representation is more compact than the TRS backend and uses
quaternions for rotation, making it suitable for applications requiring smooth
interpolation and fewer parameters.</p>
<p>Performance Notes:
This backend matches the behavior of the C++ Momentum code, ensuring consistency
with the reference implementation. However, the TRS backend may be 25-50% faster
in PyTorch due to not requiring quaternion normalization operations, though the
exact performance difference may vary depending on the specific use case.</p>
<p>Key Functions:
- global_skel_state_from_local_skel_state: Forward kinematics from local to global joint states
- skin_points_from_skel_state: Linear blend skinning using skeleton states
- local_skel_state_from_joint_params: Convert joint parameters to local states</p>
<p>Related Modules:
- trs_backend: Alternative backend using separate translation/rotation/scale tensors
- skel_state: Core skeleton state operations and utilities
- quaternion: Quaternion math operations used by this backend</p>
<dl class="py class">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymomentum.backend.skel_state_backend.</span></span><span class="sig-name descname"><span class="pre">GlobalSkelStateFromLocalSkelStateJIT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code></p>
<p>PyTorch autograd function for differentiable forward kinematics using skeleton states.</p>
<p>This class implements automatic differentiation for the forward kinematics operation,
allowing gradients to flow from global joint states back to local joint states.
The forward pass computes global states efficiently while saving intermediate results
for the backward pass.</p>
<dl class="simple">
<dt>Note:</dt><dd><p>This class is used internally by global_skel_state_from_local_skel_state when
not in JIT mode. It provides gradient computation capabilities that are not
available in pure JIT-compiled functions.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.backward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_global_skel_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.backward" title="Link to this definition"></a></dt>
<dd><p>Define a formula for differentiating the operation with backward mode automatic differentiation.</p>
<p>This function is to be overridden by all subclasses.
(Defining this function is equivalent to defining the <code class="docutils literal notranslate"><span class="pre">vjp</span></code> function.)</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward" title="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward" title="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.backward" title="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward" title="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computed w.r.t. the
output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_skel_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.forward" title="Link to this definition"></a></dt>
<dd><p>Define the forward of the custom autograd Function.</p>
<p>This function is to be overridden by all subclasses.
There are two ways to define forward:</p>
<p>Usage 1 (Combined forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p></li>
<li><p>See <span class="xref std std-ref">combining-forward-context</span> for more details</p></li>
</ul>
<p>Usage 2 (Separate forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The forward no longer accepts a ctx argument.</p></li>
<li><p>Instead, you must also override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.setup_context()</span></code>
staticmethod to handle setting up the <code class="docutils literal notranslate"><span class="pre">ctx</span></code> object.
<code class="docutils literal notranslate"><span class="pre">output</span></code> is the output of the forward, <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are a Tuple of inputs
to the forward.</p></li>
<li><p>See <span class="xref std std-ref">extending-autograd</span> for more details</p></li>
</ul>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.setup_context">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">setup_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.GlobalSkelStateFromLocalSkelStateJIT.setup_context" title="Link to this definition"></a></dt>
<dd><p>There are two ways to define the forward pass of an autograd.Function.</p>
<p>Either:</p>
<ol class="arabic simple">
<li><p>Override forward with the signature <code class="docutils literal notranslate"><span class="pre">forward(ctx,</span> <span class="pre">*args,</span> <span class="pre">**kwargs)</span></code>.
<code class="docutils literal notranslate"><span class="pre">setup_context</span></code> is not overridden. Setting up the ctx for backward
happens inside the <code class="docutils literal notranslate"><span class="pre">forward</span></code>.</p></li>
<li><p>Override forward with the signature <code class="docutils literal notranslate"><span class="pre">forward(*args,</span> <span class="pre">**kwargs)</span></code> and
override <code class="docutils literal notranslate"><span class="pre">setup_context</span></code>. Setting up the ctx for backward happens
inside <code class="docutils literal notranslate"><span class="pre">setup_context</span></code> (as opposed to inside the <code class="docutils literal notranslate"><span class="pre">forward</span></code>)</p></li>
</ol>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.forward()</span></code> and <span class="xref std std-ref">extending-autograd</span> for more details.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.skel_state_backend.</span></span><span class="sig-name descname"><span class="pre">global_skel_state_from_local_skel_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_skel_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state" title="Link to this definition"></a></dt>
<dd><p>Compute global skeleton state from local joint transformations (user-facing wrapper).</p>
<p>This is the main entry point for forward kinematics using skeleton states. It automatically
selects between JIT-compiled and autograd-enabled implementations based on the execution context.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>local_skel_state: Local joint transformations, shape (batch_size, num_joints, 8).</dt><dd><p>Each joint contains [tx, ty, tz, qx, qy, qz, qw, s] parameters.</p>
</dd>
<dt>prefix_mul_indices: List of [child_index, parent_index] tensor pairs defining</dt><dd><p>the kinematic hierarchy traversal order.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>global_skel_state: Global joint transformations, shape (batch_size, num_joints, 8).</dt><dd><p>Each joint contains the composed transformation from root to that joint.</p>
</dd>
</dl>
</dd>
<dt>Note:</dt><dd><p>When called within torch.jit.script or torch.jit.trace context, uses the JIT-compiled
implementation for maximum performance. Otherwise, uses the autograd-enabled version
for gradient computation.</p>
</dd>
<dt>See Also:</dt><dd><p><code class="xref py py-func docutils literal notranslate"><span class="pre">global_skel_state_from_local_skel_state_impl()</span></code>: JIT implementation
<code class="xref py py-func docutils literal notranslate"><span class="pre">local_skel_state_from_joint_params()</span></code>: Convert joint parameters to local states</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state_backprop">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.skel_state_backend.</span></span><span class="sig-name descname"><span class="pre">global_skel_state_from_local_skel_state_backprop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">global_skel_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_global_skel_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate_results</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_double_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state_backprop" title="Link to this definition"></a></dt>
<dd><p>Compute gradients for local skeleton state through backpropagation.</p>
<p>This function implements the backward pass for forward kinematics, computing
gradients of the loss with respect to local joint states given gradients
with respect to global joint states.</p>
<p>The backpropagation uses the intermediate results saved during the forward
pass to efficiently compute gradients without recomputing the full forward
kinematics chain.</p>
<p>Gradient Flow:
For each joint j with parent p, the backward pass computes:
∂L/∂local_j = ∂L/∂global_j * ∂global_j/∂local_j</p>
<p>Where the Jacobian ∂global_j/∂local_j depends on the parent’s global state
and is computed using the chain rule through similarity transformation composition.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>global_skel_state: Global joint states from forward pass, shape (batch_size, num_joints, 8).</dt><dd><p>These states are modified in-place during backpropagation.</p>
</dd>
<dt>grad_global_skel_state: Gradients w.r.t. global joint states, shape (batch_size, num_joints, 8).</dt><dd><p>Input gradients from downstream computations (e.g., skinning loss).</p>
</dd>
<dt>prefix_mul_indices: List of [child_index, parent_index] tensor pairs that defined</dt><dd><p>the forward pass traversal order. Backprop processes these in reverse.</p>
</dd>
<dt>intermediate_results: List of intermediate joint states saved during forward pass.</dt><dd><p>Required to compute accurate gradients without numerical drift.</p>
</dd>
<dt>use_double_precision: If True, performs computations in float64 for numerical stability.</dt><dd><p>Recommended for deep kinematic chains and precise gradient computation.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>grad_local_skel_state: Gradients w.r.t. local joint states, shape (batch_size, num_joints, 8).</dt><dd><p>These gradients can be used to update joint parameters via optimization.</p>
</dd>
</dl>
</dd>
<dt>Note:</dt><dd><p>This function processes the kinematic chain in reverse order of the forward pass,
accumulating gradients from children to parents while reconstructing intermediate states.</p>
</dd>
<dt>See Also:</dt><dd><p><code class="xref py py-func docutils literal notranslate"><span class="pre">global_skel_state_from_local_skel_state_impl()</span></code>: Forward pass implementation</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state_no_grad">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.skel_state_backend.</span></span><span class="sig-name descname"><span class="pre">global_skel_state_from_local_skel_state_no_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_skel_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_intermediate_results</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_double_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.global_skel_state_from_local_skel_state_no_grad" title="Link to this definition"></a></dt>
<dd><p>Compute global skeleton state without gradient tracking.</p>
<p>This is a convenience wrapper around global_skel_state_from_local_skel_state_impl
that explicitly disables gradient computation using torch.no_grad(). Useful for
inference-only forward passes to reduce memory usage.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>local_skel_state: Local joint transformations, shape (batch_size, num_joints, 8)
prefix_mul_indices: List of [child_index, parent_index] tensor pairs
save_intermediate_results: Whether to save intermediate states for backprop
use_double_precision: Whether to use float64 for numerical stability</p>
</dd>
<dt>Returns:</dt><dd><p>global_skel_state: Global joint transformations, shape (batch_size, num_joints, 8)
intermediate_results: List of intermediate joint states from forward pass</p>
</dd>
<dt>See Also:</dt><dd><p><code class="xref py py-func docutils literal notranslate"><span class="pre">global_skel_state_from_local_skel_state_impl()</span></code>: Implementation function</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.skel_state_backend.unpose_from_momentum_global_joint_state">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.skel_state_backend.</span></span><span class="sig-name descname"><span class="pre">unpose_from_momentum_global_joint_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_joint_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binded_joint_state_inv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skin_indices_flattened</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skin_weights_flattened</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vert_indices_flattened</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_high_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#pymomentum.backend.skel_state_backend.unpose_from_momentum_global_joint_state" title="Link to this definition"></a></dt>
<dd><p>The inverse function of skinning().
WARNING: the precision is low…</p>
<dl>
<dt>Args:</dt><dd><p>verts: [batch_size, num_verts, 3]
global_joint_state (th.Tensor): (B, J, 8)
binded_joint_state (th.Tensor): (J, 8)
skin_indices_flattened: (N, ) LBS skinning nbr joint indices
skin_weights_flattened: (N, ) LBS skinning nbr joint weights
vert_indices_flattened: (N, ) LBS skinning nbr corresponding vertex indices
with_high_precision: if True, use high precision solver (LDLT),</p>
<blockquote>
<div><p>but requires a cuda device sync</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pymomentum.backend.trs_backend">
<span id="pymomentum-backend-trs-backend-module"></span><h3>pymomentum.backend.trs_backend module<a class="headerlink" href="#module-pymomentum.backend.trs_backend" title="Link to this heading"></a></h3>
<p>TRS Backend for PyMomentum</p>
<p>This module provides efficient forward kinematics and skinning operations using
the TRS (Translation-Rotation-Scale) representation where each transformation
component is stored separately.</p>
<p>The TRS representation uses separate tensors for translation (3D), rotation matrices (3x3),
and scale factors (1D), making it suitable for applications that need explicit access
to individual transformation components.</p>
<p>Performance Notes:
This backend is typically 25-50% faster than the skeleton state backend in PyTorch,
likely due to not requiring quaternion normalization operations. While it doesn’t
match the C++ reference implementation exactly (use skel_state_backend for that),
it provides excellent performance for PyTorch-based applications.</p>
<p>Key Functions:
- global_trs_state_from_local_trs_state: Forward kinematics from local to global joint states
- skin_points_from_trs_state: Linear blend skinning using TRS transformations
- local_trs_state_from_joint_params: Convert joint parameters to local TRS states</p>
<p>Related Modules:
- skel_state_backend: Alternative backend using compact 8-parameter skeleton states
- trs: Core TRS transformation operations and utilities</p>
<dl class="py class">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymomentum.backend.trs_backend.</span></span><span class="sig-name descname"><span class="pre">ForwardKinematicsFromLocalTransformationJIT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.backward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_joint_state_t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_joint_state_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_joint_state_s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.backward" title="Link to this definition"></a></dt>
<dd><p>Define a formula for differentiating the operation with backward mode automatic differentiation.</p>
<p>This function is to be overridden by all subclasses.
(Defining this function is equivalent to defining the <code class="docutils literal notranslate"><span class="pre">vjp</span></code> function.)</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward" title="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward" title="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.backward" title="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward" title="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computed w.r.t. the
output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_state_t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_state_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_state_s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.forward" title="Link to this definition"></a></dt>
<dd><p>Define the forward of the custom autograd Function.</p>
<p>This function is to be overridden by all subclasses.
There are two ways to define forward:</p>
<p>Usage 1 (Combined forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p></li>
<li><p>See <span class="xref std std-ref">combining-forward-context</span> for more details</p></li>
</ul>
<p>Usage 2 (Separate forward and ctx):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The forward no longer accepts a ctx argument.</p></li>
<li><p>Instead, you must also override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.setup_context()</span></code>
staticmethod to handle setting up the <code class="docutils literal notranslate"><span class="pre">ctx</span></code> object.
<code class="docutils literal notranslate"><span class="pre">output</span></code> is the output of the forward, <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are a Tuple of inputs
to the forward.</p></li>
<li><p>See <span class="xref std std-ref">extending-autograd</span> for more details</p></li>
</ul>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.setup_context">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">setup_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#pymomentum.backend.trs_backend.ForwardKinematicsFromLocalTransformationJIT.setup_context" title="Link to this definition"></a></dt>
<dd><p>There are two ways to define the forward pass of an autograd.Function.</p>
<p>Either:</p>
<ol class="arabic simple">
<li><p>Override forward with the signature <code class="docutils literal notranslate"><span class="pre">forward(ctx,</span> <span class="pre">*args,</span> <span class="pre">**kwargs)</span></code>.
<code class="docutils literal notranslate"><span class="pre">setup_context</span></code> is not overridden. Setting up the ctx for backward
happens inside the <code class="docutils literal notranslate"><span class="pre">forward</span></code>.</p></li>
<li><p>Override forward with the signature <code class="docutils literal notranslate"><span class="pre">forward(*args,</span> <span class="pre">**kwargs)</span></code> and
override <code class="docutils literal notranslate"><span class="pre">setup_context</span></code>. Setting up the ctx for backward happens
inside <code class="docutils literal notranslate"><span class="pre">setup_context</span></code> (as opposed to inside the <code class="docutils literal notranslate"><span class="pre">forward</span></code>)</p></li>
</ol>
<p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.forward()</span></code> and <span class="xref std std-ref">extending-autograd</span> for more details.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.trs_backend.</span></span><span class="sig-name descname"><span class="pre">global_trs_state_from_local_trs_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_state_t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_state_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_state_s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state" title="Link to this definition"></a></dt>
<dd><p>Compute global TRS state from local joint transformations (user-facing wrapper).</p>
<p>This is the main entry point for forward kinematics using TRS states. It automatically
selects between JIT-compiled and autograd-enabled implementations based on the execution context.</p>
<dl>
<dt>Args:</dt><dd><p>local_state_t: Local joint translations, shape (batch_size, num_joints, 3).
local_state_r: Local joint rotations, shape (batch_size, num_joints, 3, 3).
local_state_s: Local joint scales, shape (batch_size, num_joints, 1).
prefix_mul_indices: List of [child_index, parent_index] tensor pairs defining</p>
<blockquote>
<div><p>the kinematic hierarchy traversal order.</p>
</div></blockquote>
</dd>
<dt>Returns:</dt><dd><p>global_state_t: Global joint translations, shape (batch_size, num_joints, 3).
global_state_r: Global joint rotations, shape (batch_size, num_joints, 3, 3).
global_state_s: Global joint scales, shape (batch_size, num_joints, 1).</p>
</dd>
<dt>Note:</dt><dd><p>When called within torch.jit.script or torch.jit.trace context, uses the JIT-compiled
implementation for maximum performance. Otherwise, uses the autograd-enabled version
for gradient computation.</p>
</dd>
<dt>See Also:</dt><dd><p><code class="xref py py-func docutils literal notranslate"><span class="pre">global_trs_state_from_local_trs_state_impl()</span></code>: JIT implementation
<code class="xref py py-func docutils literal notranslate"><span class="pre">local_trs_state_from_joint_params()</span></code>: Convert joint parameters to local states</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state_forward_only">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.trs_backend.</span></span><span class="sig-name descname"><span class="pre">global_trs_state_from_local_trs_state_forward_only</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_state_t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_state_r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_state_s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_mul_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state_forward_only" title="Link to this definition"></a></dt>
<dd><p>Compute global TRS state from local joint transformations (forward-only wrapper).</p>
<p>This is a forward-only version that bypasses autograd completely, used when
gradients are not needed and maximum performance is required.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>local_state_t: Local joint translations, shape (batch_size, num_joints, 3).
local_state_r: Local joint rotations, shape (batch_size, num_joints, 3, 3).
local_state_s: Local joint scales, shape (batch_size, num_joints, 1).
prefix_mul_indices: List of [child_index, parent_index] tensor pairs.</p>
</dd>
<dt>Returns:</dt><dd><p>global_state_t: Global joint translations, shape (batch_size, num_joints, 3).
global_state_r: Global joint rotations, shape (batch_size, num_joints, 3, 3).
global_state_s: Global joint scales, shape (batch_size, num_joints, 1).</p>
</dd>
<dt>See Also:</dt><dd><p><a class="reference internal" href="#pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state" title="pymomentum.backend.trs_backend.global_trs_state_from_local_trs_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">global_trs_state_from_local_trs_state()</span></code></a>: Main user-facing function with autograd</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.trs_backend.unpose_from_global_joint_state">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.trs_backend.</span></span><span class="sig-name descname"><span class="pre">unpose_from_global_joint_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skin_indices_flattened</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skin_weights_flattened</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vert_indices_flattened</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_high_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#pymomentum.backend.trs_backend.unpose_from_global_joint_state" title="Link to this definition"></a></dt>
<dd><p>The inverse function of skinning().
WARNING: the precision is low…</p>
<dl>
<dt>Args:</dt><dd><p>verts: [batch_size, num_verts, 3]
t: (B, J, 3) Translation of the joints
r: (B, J, 3, 3) Rotation of the joints
s: (B, J, 1) Scale of the joints
t0: (J, 3) Translation of inverse bind pose
r0: (J, 3, 3) Rotation of inverse bind pose
skin_indices_flattened: (N, ) LBS skinning nbr joint indices
skin_weights_flattened: (N, ) LBS skinning nbr joint weights
vert_indices_flattened: (N, ) LBS skinning nbr corresponding vertex indices
with_high_precision: if True, use high precision solver (LDLT),</p>
<blockquote>
<div><p>but requires a cuda device sync</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pymomentum.backend.utils">
<span id="pymomentum-backend-utils-module"></span><h3>pymomentum.backend.utils module<a class="headerlink" href="#module-pymomentum.backend.utils" title="Link to this heading"></a></h3>
<section id="backend-utility-functions-for-pymomentum">
<h4>Backend Utility Functions for PyMomentum<a class="headerlink" href="#backend-utility-functions-for-pymomentum" title="Link to this heading"></a></h4>
<p>This module provides utility functions that are specific to backend operations
and were previously available in real_lbs_pytorch but are now implemented
within pymomentum for the backend porting effort.</p>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="pymomentum.backend.utils.LBSAdapter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pymomentum.backend.utils.</span></span><span class="sig-name descname"><span class="pre">LBSAdapter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">character</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="geometry.html#pymomentum.geometry.Character" title="pymomentum.geometry.Character"><span class="pre">Character</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pymomentum.backend.utils.LBSAdapter" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Adapter class to make pymomentum Character compatible with LBS interface.</p>
<p>This adapter provides a compatibility layer that allows pymomentum Character objects
to be used in tests and code that originally expected the LBS interface from the
real_lbs_pytorch library. It extracts and converts the necessary properties from
a Character object into the expected tensor format and provides the methods that
the original LBS interface had.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.utils.LBSAdapter.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">character</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="geometry.html#pymomentum.geometry.Character" title="pymomentum.geometry.Character"><span class="pre">Character</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#pymomentum.backend.utils.LBSAdapter.__init__" title="Link to this definition"></a></dt>
<dd><p>Initialize the LBS adapter with a pymomentum Character.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>character</strong> – The pymomentum Character to adapt</p></li>
<li><p><strong>device</strong> – Device to place tensors on (default: “cpu”)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.utils.LBSAdapter.assemble_pose_and_scale_">
<span class="sig-name descname"><span class="pre">assemble_pose_and_scale_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#pymomentum.backend.utils.LBSAdapter.assemble_pose_and_scale_" title="Link to this definition"></a></dt>
<dd><p>Assemble pose and scale parameters into model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pose</strong> – Pose parameters tensor</p></li>
<li><p><strong>scale</strong> – Scale parameters tensor</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Combined model parameters tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pymomentum.backend.utils.LBSAdapter.device">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#pymomentum.backend.utils.LBSAdapter.device" title="Link to this definition"></a></dt>
<dd><p>Get the device that tensors are stored on.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pymomentum.backend.utils.LBSAdapter.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pymomentum.backend.utils.LBSAdapter" title="pymomentum.backend.utils.LBSAdapter"><span class="pre">LBSAdapter</span></a></span></span><a class="headerlink" href="#pymomentum.backend.utils.LBSAdapter.to" title="Link to this definition"></a></dt>
<dd><p>Move adapter to specified device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Target device to move tensors to</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>New LBSAdapter instance on the target device</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.utils.calc_fk_prefix_multiplication_indices">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.utils.</span></span><span class="sig-name descname"><span class="pre">calc_fk_prefix_multiplication_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">joint_parents</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.utils.calc_fk_prefix_multiplication_indices" title="Link to this definition"></a></dt>
<dd><p>Calculate prefix multiplication indices for forward kinematics.</p>
<p>This function computes the indices needed for efficient prefix multiplication
during forward kinematics computation. The algorithm builds kinematic chains
for each joint and determines the multiplication order for parallel processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>joint_parents</strong> (<em>torch.Tensor</em>) – Parent joint index for each joint. For root joint, its parent is -1.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of prefix multiplication indices per level. For each level,
index[0] is the source and index[1] is the target indices.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pymomentum.backend.utils.flatten_skinning_weights_and_indices">
<span class="sig-prename descclassname"><span class="pre">pymomentum.backend.utils.</span></span><span class="sig-name descname"><span class="pre">flatten_skinning_weights_and_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">skin_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skin_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pymomentum.backend.utils.flatten_skinning_weights_and_indices" title="Link to this definition"></a></dt>
<dd><p>Decompress LBS skinning weights and indices into flattened arrays.</p>
<p>This function takes the typical (V, 8) sparse representation of skinning weights
and indices and converts them into flattened arrays by removing zero weights,
making them suitable for efficient skinning computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>skin_weights</strong> (<em>torch.Tensor</em>) – Skinning weights tensor of shape (V, 8).</p></li>
<li><p><strong>skin_indices</strong> (<em>torch.Tensor</em>) – Skinning joint indices tensor of shape (V, 8).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of (skin_indices_flattened, skin_weights_flattened, vert_indices_flattened).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="marker_tracking.html" class="btn btn-neutral float-left" title="pymomentum.marker_tracking" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="gpu_character.html" class="btn btn-neutral float-right" title="pymomentum.gpu_character" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>